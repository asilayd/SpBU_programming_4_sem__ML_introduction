{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe17f88-70f7-433c-8fd7-4840073477e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9ff2f8-6b80-429d-9529-3daabf3a5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = {'cpu_easy': './easy/CPU_panda_classifier_state_dict.pth' , \n",
    "                    'gpu_easy': './easy/GPU_panda_classifier_state_dict.pth' , \n",
    "                        'cpu_hard': './hard/CPU_BigData_panda_classifier_state_dict.pth', \n",
    "                            'gpu_hard': './hard/GPU_BigData_panda_classifier_state_dict.pth'}\n",
    "names = [k for k in models_path.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "983d7407-3446-4732-b429-e56758a2e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PandaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PandaClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 класса: \"панда\" (0) и \"не панда\" (1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))\n",
    "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 32 * 8 * 8)  # Разворачиваем тензор перед полносвязным слоем\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5751099b-a4fd-456f-aa6c-a71ab18b6623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cpu_easy\n",
      "1 gpu_easy\n",
      "2 cpu_hard\n",
      "3 gpu_hard\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PandaClassifier(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаём объект модели\n",
    "model = PandaClassifier()\n",
    "i = 0\n",
    "for k in models_path.keys():\n",
    "    print(i, k)\n",
    "    i+=1\n",
    "model.load_state_dict(torch.load(models_path[names[int(input())]], weights_only=True))\n",
    "model.eval()  # Устанавливаем модель в режим оценки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a29488c-36f3-4e3d-a63b-2fcbc1520a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Панды на изображении нет.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Определите трансформации для изменения размера изображения\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Приведение всех изображений к размеру 32x32\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Функция для предсказания\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Добавляем batch dimension\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return \"Панда на изображении!\" if predicted.item() == 0 else \"Панды на изображении нет.\"\n",
    "\n",
    "# Пример использования\n",
    "image_path = r\"path_to_image\"\n",
    "\n",
    "result = predict_image(image_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c295b-96f0-49c9-9238-58597fabf65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
